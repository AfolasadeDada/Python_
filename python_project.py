# -*- coding: utf-8 -*-
"""Python_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Fc2ahV_FpNNqWlbGIxACaJFIXFRHKR_

## Integrated Project: Understanding Maji Ndogo's agriculture

# Data dictionary
"""

import pandas as pd # importing the Pandas package with an alias, pd
from sqlalchemy import create_engine, text # Importing the SQL interface. If this fails, run !pip install sqlalchemy in another cell.

# Create an engine for the database
engine = create_engine('sqlite:///Maji_Ndogo_farm_survey_small.db') #Make sure to have the .db file in the same directory as this notebook, and the file name matches.

with engine.connect() as connection:
    result = connection.execute(text("SELECT name FROM sqlite_master WHERE type='table';"))
    for row in result:
        print(row)

sql_query = """
SELECT *
FROM
    geographic_features as geo
JOIN
    weather_features as weather ON geo.Field_ID = weather.Field_ID
JOIN
    soil_and_crop_features as soil_crop ON geo.Field_ID = soil_crop.Field_ID
JOIN
    farm_management_features as farm_mgmt ON geo.Field_ID = farm_mgmt.Field_ID;
"""

"""With our engine and query ready, we'll use `Pandas` to execute the query. The `pd.read_sql_query` function fetches the data and loads it into a DataFrame – essentially transferring our data from the database into a familiar `Pandas` structure. If you use one query, you will import it all into `MD_agric_df`."""

# Create a connection object
with engine.connect() as connection:

    # Use Pandas to execute the query and store the result in a DataFrame
    MD_agric_df = pd.read_sql_query(text(sql_query), connection)

MD_agric_df

# Now, drop all columns named 'Field_ID'.
MD_agric_df.drop(columns = 'Field_ID', inplace = True)

"""# Data cleanup"""

# Insert your code here
MD_agric_df['Crop_type'], MD_agric_df['Annual_yield'] = MD_agric_df['Annual_yield'], MD_agric_df['Crop_type']

crop_corrections = {'wheatn': 'wheat',
                    'teaa': 'tea',
                    'cassaval': 'cassava',
                    'cassava ': 'cassava',
                    'wheat ': 'wheat',
                    'tea ': 'tea'}
MD_agric_df['Crop_type'].replace(crop_corrections, inplace=True)

MD_agric_df['Elevation'] = MD_agric_df['Elevation'].abs()

"""## Final data checkup"""

len(MD_agric_df['Crop_type'].unique())

MD_agric_df['Elevation'].min()

MD_agric_df['Annual_yield'].dtype

"""# Analysis

##Uncovering crop preferences

Now that we have our data ready, let's delve into understanding where different crops are grown in Maji Ndogo. Our initial step is to focus on tea, a key crop in Maji Ndogo. We need to determine the optimal conditions for its growth. By analyzing data related to elevation, rainfall, and soil type specifically for tea plantations, we'll start to paint a picture of where our farming systems could thrive.
"""

### START FUNCTION
def explore_crop_distribution(df,crop_filter):

    crop_data = df[df['Crop_type'] == crop_filter]

    mean_rainfall = crop_data['Rainfall'].mean()
    mean_elevation = crop_data['Elevation'].mean()

    return (mean_rainfall, mean_elevation)

### END FUNCTION

"""Input:"""

explore_crop_distribution(MD_agric_df, "tea")

explore_crop_distribution(MD_agric_df, "wheat")

"""## Finding fertile grounds

With insights into tea cultivation, let's broaden our horizons. Fertile soil is the bedrock of successful farming. By grouping our data by location and soil type, we'll pinpoint where the most fertile soils in Maji Ndogo are. These fertile zones could be prime candidates for diverse crop cultivation, maximising our yield.

We’ll group our data by soil type to see where the most fertile grounds are. This information will be vital for deciding where to deploy our farming technology.
"""

### START FUNCTION
def analyse_soil_fertility(df):

    soil_fertility_analysis = df.groupby('Soil_type')['Soil_fertility'].mean()
    return soil_fertility_analysis

### END FUNCTION

"""Input:"""

analyse_soil_fertility(MD_agric_df)

"""## Climate and geography analysis

Now, let's delve into how climate and geography influence farming. By understanding the relationship between factors like elevation, temperature, and rainfall with crop yields, we can identify the most suitable areas for different crops. This analysis is key to ensuring our automated systems are deployed in locations that will maximise their effectiveness.
"""

### START FUNCTION
def climate_geography_influence(df,column):

    # Group the data by the specified column and calculate the mean for relevant columns
    climate_geo_influence = df.groupby(column).agg({
        'Elevation': 'mean',
        'Min_temperature_C': 'mean',
        'Max_temperature_C': 'mean',
        'Rainfall': 'mean'
    })

    # Return the results
    return climate_geo_influence


### END FUNCTION

"""Input:"""

climate_geography_influence(MD_agric_df, 'Crop_type')

"""## Advanced sorting techniques"""

grouped_df = MD_agric_df.groupby("Soil_type").mean(numeric_only = True).sort_values(by="Elevation",ascending=False)
print(grouped_df.index[0])
grouped_df

### START FUNCTION
def find_ideal_fields(df):

    avg_standard_yield = df['Standard_yield'].mean()

    high_yield_fields = df[df['Standard_yield'] > avg_standard_yield]

    crop_counts = high_yield_fields['Crop_type'].value_counts()

    sorted_crops = crop_counts.sort_values(ascending=False)

    top_crop = sorted_crops.index[0]

    return top_crop

### END FUNCTION

"""Input:"""

type(find_ideal_fields(MD_agric_df))

"""# Advanced filtering techniques"""

### START FUNCTION
def find_good_conditions(df, crop_type):
    crop_df = df[df['Crop_type'] == crop_type]
    avg_standard_yield = crop_df['Standard_yield'].mean()
    high_yield_rows = crop_df[crop_df['Standard_yield'] > avg_standard_yield]
    temp_condition_rows = high_yield_rows[(high_yield_rows['Ave_temps'] >= 12) & (high_yield_rows['Ave_temps'] <= 15)]
    good_condition_rows = temp_condition_rows[temp_condition_rows['Pollution_level'] < 0.0001]
    return good_condition_rows
### END FUNCTION

"""Input:"""

find_good_conditions(MD_agric_df, "tea").shape

"""## df.query()"""

MD_agric_df.query('Standard_yield > 0.5 and Soil_type == "Loamy"')

MD_agric_df[(MD_agric_df['Standard_yield'] > 0.5) & (MD_agric_df['Soil_type'] == 'Loamy')]

"""The nice thing is, we can use `in []`, `not in []` to filter with, and also pass in variables using `@variable_name`."""

soil_types = ['Loamy', 'Sandy', 'Silt']

MD_agric_df.query('Soil_type in @soil_types')

"""# Plotting data with Pandas

Sometimes we quickly want to see a basic visualisation of our data. we can use `df.plot(kind='bar')` to make a bar plot, `df.plot(kind='hist', bins = 10)` to see the distribution of a data column, or `df.plot(kind='scatter', x='Column_on_x', y='Column_on_y')` to understand the relationship between variables.
"""

MD_agric_df.groupby('Crop_type')['Standard_yield'].mean().plot(kind='bar')

MD_agric_df['Standard_yield'].plot(kind='hist', bins =20)

MD_agric_df.plot(kind='scatter', x = "Pollution_level", y = "Standard_yield")